{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "422d4772",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from skopt.space import Real, Integer\n",
    "from modules.interface import RunModel, RunOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c5e271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Carregando o banco de dados...\n",
      "==================================================\n",
      "INICIANDO OTIMIZAÇÃO PARA LIGHTGBM\n",
      "==================================================\n",
      "Optimization finished.\n",
      "Best score (mean_absolute_error): 0.2818\n",
      "Best parameters: {'learning_rate': 0.08032145496250154, 'num_leaves': np.int64(594), 'max_depth': np.int64(667), 'feature_fraction': 0.7414033489099505, 'bagging_fraction': 1.0, 'bagging_freq': np.int64(1), 'lambda_l1': 0.9148060866796668, 'lambda_l2': 0.5}\n",
      "\n",
      "To train the final model with these parameters, call the '.fit_best_model()' method.\n",
      "Training the final model with the best parameters...\n",
      "Final model has been trained and is stored in the '.best_model_' attribute.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<modules.optimizers.BayesianOptimization at 0x28ac7c52660>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- INÍCIO DO SCRIPT DE TESTE ---\n",
    "\n",
    "# 1. Carregar o Banco de Dados (California Housing)\n",
    "print(\"1. Carregando o banco de dados...\")\n",
    "housing = fetch_california_housing()\n",
    "X = pd.DataFrame(housing.data, columns=housing.feature_names)\n",
    "y = pd.Series(housing.target)\n",
    "\n",
    "# 2. Dividir os dados em Conjunto de Treino e Teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- OTIMIZAÇÃO PARA LIGHTGBM ---\n",
    "print(\"=\"*50)\n",
    "print(\"INICIANDO OTIMIZAÇÃO PARA LIGHTGBM\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "space_lgbm = [\n",
    "    Real(name='learning_rate', low = 0.01 , high = 0.9),\n",
    "    Integer(name='num_leaves', low = 200, high = 700),\n",
    "    Integer(name='max_depth', low = 200, high = 700),\n",
    "    Real(name='feature_fraction', low = 0.5 , high = 1),\n",
    "    Real(name='bagging_fraction', low = 0.7 , high = 1),\n",
    "    Integer(name='bagging_freq', low = 1, high = 10),\n",
    "    Real(name='lambda_l1',low = 0.0, high = 1),\n",
    "    Real(name='lambda_l2',low = 0.5, high = 1)\n",
    "]\n",
    "\n",
    "fixed_params_lgbm = {\n",
    "    'objective': 'mae', \n",
    "    'metric': 'mae', \n",
    "    'num_iterations ': 300,\n",
    "    'random_state': 42, \n",
    "    'n_jobs': -1, \n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "calibration_kwargs = {'callbacks':[lgb.early_stopping(stopping_rounds=10, verbose=False)]}\n",
    "optimization_kwargs = {'n_initial_points': 5,\n",
    "                        'n_calls': 10,\n",
    "                        'initial_point_generator': 'lhs',\n",
    "                        'random_state': 42,\n",
    "\n",
    "                       \n",
    "                       }\n",
    "\n",
    "# Simplesmente passe 'model_type=\"lightgbm\"'\n",
    "optimizer_lgbm = RunOptimization()\n",
    "results=optimizer_lgbm.run(opt_class='gp_minimize',\n",
    "    model_class=\"lgbm\",\n",
    "    datasets=[X_train, X_test, y_train, y_test],\n",
    "    space=space_lgbm, \n",
    "    fixed_params=fixed_params_lgbm,\n",
    "    metric='mae',\n",
    "    calibration_kwargs=calibration_kwargs,\n",
    "    optimization_kwargs= optimization_kwargs\n",
    "\n",
    ")\n",
    "\n",
    "optimizer_lgbm.optimizer[0].fit_best_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6deee96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Melhor MAE para LightGBM: 0.2818\n",
      "Melhores parâmetros: [0.08032145496250154, np.int64(594), np.int64(667), 0.7414033489099505, 1.0, np.int64(1), 0.9148060866796668, 0.5]\n",
      "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
      "20046  1.6812      25.0  4.192201   1.022284      1392.0  3.877437     36.06   \n",
      "3024   2.5313      30.0  5.039384   1.193493      1565.0  2.679795     35.14   \n",
      "15663  3.4801      52.0  3.977155   1.185877      1310.0  1.360332     37.80   \n",
      "20484  5.7376      17.0  6.163636   1.020202      1705.0  3.444444     34.28   \n",
      "9814   3.7250      34.0  5.492991   1.028037      1063.0  2.483645     36.62   \n",
      "...       ...       ...       ...        ...         ...       ...       ...   \n",
      "15362  4.6050      16.0  7.002212   1.066372      1351.0  2.988938     33.36   \n",
      "16623  2.7266      28.0  6.131915   1.256738      1650.0  2.340426     35.36   \n",
      "18086  9.2298      25.0  7.237676   0.947183      1585.0  2.790493     37.31   \n",
      "2144   2.7850      36.0  5.289030   0.983122      1227.0  2.588608     36.77   \n",
      "3665   3.5521      17.0  3.988839   1.033482      1671.0  3.729911     34.22   \n",
      "\n",
      "       Longitude  \n",
      "20046    -119.01  \n",
      "3024     -119.46  \n",
      "15663    -122.44  \n",
      "20484    -118.72  \n",
      "9814     -121.93  \n",
      "...          ...  \n",
      "15362    -117.22  \n",
      "16623    -120.83  \n",
      "18086    -122.05  \n",
      "2144     -119.76  \n",
      "3665     -118.37  \n",
      "\n",
      "[4128 rows x 8 columns]\n",
      "20046    0.47700\n",
      "3024     0.45800\n",
      "15663    5.00001\n",
      "20484    2.18600\n",
      "9814     2.78000\n",
      "          ...   \n",
      "15362    2.63300\n",
      "16623    2.66800\n",
      "18086    5.00001\n",
      "2144     0.72300\n",
      "3665     1.51500\n",
      "Length: 4128, dtype: float64\n",
      "20046    0.47700\n",
      "3024     0.45800\n",
      "15663    5.00001\n",
      "20484    2.18600\n",
      "9814     2.78000\n",
      "          ...   \n",
      "15362    2.63300\n",
      "16623    2.66800\n",
      "18086    5.00001\n",
      "2144     0.72300\n",
      "3665     1.51500\n",
      "Length: 4128, dtype: float64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nMelhor MAE para LightGBM: {results[0].fun:.4f}\")\n",
    "print(f\"Melhores parâmetros: {results[0].x}\")\n",
    "\n",
    "print(optimizer_lgbm.optimizer[0].X_test)\n",
    "print(optimizer_lgbm.optimizer[0].y_test)\n",
    "print(optimizer_lgbm.optimizer[0].y_test)\n",
    "\n",
    "print(type(optimizer_lgbm.optimizer[0].X_test))\n",
    "print(type(optimizer_lgbm.optimizer[0].y_test))\n",
    "print(type(optimizer_lgbm.optimizer[0].y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "068e9477",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ricar\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\lightgbm\\engine.py:204: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    }
   ],
   "source": [
    "parameters_run_model = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"objective\": \"mae\",\n",
    "    \"metric\": [\"mae\"],\n",
    "    \"num_leaves\": 30,\n",
    "    \"max_depth\": 7,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"feature_fraction\": 0.9,\n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"bagging_freq\": 5,\n",
    "    \"num_boost_round\": 1000,\n",
    "    \"early_stopping_rounds\": 5,\n",
    "    \"lambda_l1\": 0.0,\n",
    "    \"lambda_l2\": 0.0,\n",
    "    \"force_row_wise\": True,\n",
    "    \"verbosity\": -1\n",
    "}\n",
    "\n",
    "calibration_kwargs = {'callbacks':[lgb.early_stopping(stopping_rounds=10, verbose=False)]}\n",
    "\n",
    "# Simplesmente passe 'model_type=\"lightgbm\"'\n",
    "lgbm_model = RunModel()\n",
    "results=lgbm_model.run(\n",
    "    model_class=\"lgbm\",\n",
    "    datasets=[X_train, X_test, y_train, y_test],\n",
    "    params=parameters_run_model,\n",
    "    calibration_kwargs= calibration_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1c9acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'modules.models.LGBMTrainning'>\n",
      "<class 'list'>\n",
      "<class 'lightgbm.basic.Booster'>\n",
      "<class 'numpy.ndarray'>\n",
      "[0.49308831 0.88583469 4.62602639 ... 5.04322149 0.74325382 1.62495011]\n"
     ]
    }
   ],
   "source": [
    "print(type(lgbm_model.models))\n",
    "print(type(lgbm_model.models[0]))\n",
    "print(type(results))\n",
    "print(type(results[0]))\n",
    "y_pred=lgbm_model.models[0].predict(results[0])\n",
    "\n",
    "print(type(y_pred))\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7fbe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Agora, para otimizar outro modelo, só mudamos o tipo e os parâmetros!\n",
    "# optimizer_xgb = BayesianOptimization(\n",
    "#     model_type=\"xgboost\",\n",
    "#     X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test,\n",
    "#     space=space_xgb, fixed_params=fixed_params_xgb\n",
    "# )\n",
    "# resultado_xgb = optimizer_xgb.run(n_calls=15, random_state=42)\n",
    "# print(f\"\\nMelhor MAE para XGBoost: {resultado_xgb.fun:.4f}\")\n",
    "# print(f\"Melhores parâmetros: {resultado_xgb.x}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
